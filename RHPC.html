<!DOCTYPE html>
<html>
<head>
  <title>Using R in HPC</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Using R in HPC',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'RHPC_files/logo.png',
              },

      // Author information
      presenters: [
            {
        name:  'Pedro Ojeda' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #aaaaaa;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
            div.sourceCode
              {   }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #ff0000; font-weight: bold; } /* Alert */
            code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #7d9029; } /* Attribute */
            code span.bn { color: #40a070; } /* BaseN */
            code span.bu { } /* BuiltIn */
            code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #4070a0; } /* Char */
            code span.cn { color: #880000; } /* Constant */
            code span.co { color: #60a0b0; font-style: italic; } /* Comment */
            code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #ba2121; font-style: italic; } /* Documentation */
            code span.dt { color: #902000; } /* DataType */
            code span.dv { color: #40a070; } /* DecVal */
            code span.er { color: #ff0000; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #40a070; } /* Float */
            code span.fu { color: #06287e; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #007020; font-weight: bold; } /* Keyword */
            code span.op { color: #666666; } /* Operator */
            code span.ot { color: #007020; } /* Other */
            code span.pp { color: #bc7a00; } /* Preprocessor */
            code span.sc { color: #4070a0; } /* SpecialChar */
            code span.ss { color: #bb6688; } /* SpecialString */
            code span.st { color: #4070a0; } /* String */
            code span.va { color: #19177c; } /* Variable */
            code span.vs { color: #4070a0; } /* VerbatimString */
            code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(RHPC_files/logo.png) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>

  <link rel="stylesheet" href="custom.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="RHPC_files/logo.png"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">Feb., 2021</p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>Desktop PC vs. HPC architectures</h2></hgroup><article  id="desktop-pc-vs.-hpc-architectures">

<img width="700px" src='Images/kebne_arch.png' title=''/>

</article></slide><slide class=""><hgroup><h2>Types of programs</h2></hgroup><article  id="types-of-programs">

<p>Programs could be of different types:</p>

<ul>
<li><p>Compute bound if they use mainly CPU power (more cores can help)</p></li>
<li><p>Memory bound if the bottlenecks are allocating memory, copying/duplicating objects (large memory nodes on Kebnekaise)</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Parallelization levels</h2></hgroup><article  id="parallelization-levels">

<ul>
<li><p>Implicit parallelism is included in some packages, one only needs to assign the number of workers (threads)</p></li>
<li><p>Explicit parallelism requires the intervention of the user to write the proper parallelization instruction (Rmpi for instance)</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Using R in HPC</h2></hgroup><article  id="using-r-in-hpc">

<p>There are several versions of R installed on Kebnekaise</p>

<pre class = 'prettyprint lang-r'>&gt;ml spider R
     Versions:
        R/3.3.1
        R/3.4.4-X11-20180131
        R/3.5.1-Python-2.7.15
        R/3.5.1
        R/3.6.0
        R/3.6.2
        R/4.0.0
        
&gt;ml spider R/3.6.0   #search for the modules needed by R
  You will need to load all module(s) on any one of the lines below before the &quot;R/3.6.0&quot; 
      GCC/8.2.0-2.31.1  OpenMPI/3.1.3</pre>

</article></slide><slide class=""><hgroup><h2>Using R in HPC</h2></hgroup><article  id="using-r-in-hpc-1">

<pre class = 'prettyprint lang-r'>&gt;R --help

Usage: R [options] [&lt; infile] [&gt; outfile]
   or: R CMD command [arguments]

Start R, a system for statistical computation and graphics, with the
specified options, or invoke an R tool via the &#39;R CMD&#39; interface.

Options:
  -h, --help            Print short help message and exit
  --version             Print version info and exit
  --encoding=ENC        Specify encoding to be used for stdin
  --encoding ENC
  RHOME         Print path to R home directory and exit
  --save                Do save workspace at the end of the session
  --no-save             Don&#39;t save it
  --no-environ          Don&#39;t read the site and user environment files</pre>

</article></slide><slide class=""><hgroup><h2>Adding your own packages in R</h2></hgroup><article  id="adding-your-own-packages-in-r">

<ul>
<li><a href='https://www.hpc2n.umu.se/resources/software/user_installed/r' title=''>https://www.hpc2n.umu.se/resources/software/user_installed/r</a></li>
</ul>

</article></slide><slide class=""><hgroup><h2>SLURM workload manager</h2></hgroup><article  id="slurm-workload-manager">

<img width="660px" src='Images/slurm.png' title=''/>

</article></slide><slide class=""><hgroup><h2>Running serial jobs</h2></hgroup><article  id="running-serial-jobs">

<img width="800px" src='Images/using-r-hpc-serial.png' title=''/>

</article></slide><slide class=""><hgroup><h2>Running your script</h2></hgroup><article  id="running-your-script">

<ul>
<li>Transfer your files to Kebnekaise</li>
<li>Submit your job with: <strong>sbatch job.sh</strong></li>
<li>In case sbatch complains about the DOS format use the command:</li>
</ul>

<p><strong>dos2unix job.sh</strong></p>

<p>before submitting your job.</p>

<ul>
<li>More information: <a href='https://www.hpc2n.umu.se/resources/software/r' title=''>https://www.hpc2n.umu.se/resources/software/r</a></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Running several independent jobs</h2></hgroup><article  id="running-several-independent-jobs">

<p>One can use <strong>job arrays</strong> option in SLURM to run independent instances of a program:</p>

<pre class = 'prettyprint lang-r'>#!/bin/bash
#SBATCH -A Project_ID
#Asking for 10 min.
#SBATCH -t 00:12:00
#SBATCH --array=1-28
##Writing the output and error files
#SBATCH --output=Array_test.%A_%a.out
#SBATCH --error=Array_test.%A_%a.error

ml GCC/8.2.0-2.31.1  OpenMPI/3.1.3
ml R/3.6.0

R --no-save --no-restore -f script.R</pre>

</article></slide><slide class=""><hgroup><h2>Running R in parallel mode</h2></hgroup><article  id="running-r-in-parallel-mode">

<img width="800px" src='Images/using-r-hpc-parallel.png' title=''/>

</article></slide><slide class=""><hgroup><h2>Monitoring your jobs</h2></hgroup><article  id="monitoring-your-jobs">

<ul>
<li><p><strong>squeue -a -u username</strong> list your jobs on the queue</p></li>
<li><p><strong>projinfo</strong> displays the project’s usage</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Parallel packages</h2></hgroup><article  id="parallel-packages">

<p>Some packages like BLAS/LAPACK have an implicit parallelization layer that can be activated by setting a number of threads.</p>

<p>On Kebnekaise the OpenBLAS libraries are available and can use implicit parallelism:</p>

<pre class = 'prettyprint lang-r'>sessionInfo()

R version 3.6.0 (2019-04-26)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.6 LTS

Matrix products: default
BLAS/LAPACK: /cvmfs/.../8.2.0-2.31.1/OpenBLAS/0.3.5/lib/libopenblas_haswellp-r0.3.5.so</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages</h2></hgroup><article  id="parallel-packages-1">

<p>The number of threads can be controlled with the <em>RhpcBLASctl</em> package and setting the number of threads:</p>

<pre class = 'prettyprint lang-r'>library(RhpcBLASctl)
n &lt;- 5000; nsim &lt;- 3                 #matrix size nxn; nr. independent simulations
set.seed(123); summa &lt;- 0; x &lt;- 0; blas_set_num_threads(1)  #set the number of threads
for (i in 1:nsim) {
  m &lt;- matrix(rnorm(n^2), n); a &lt;- crossprod(m)   #random matrix and symmetrize it
  timing &lt;- system.time({
    x &lt;- eigen(a, symmetric=TRUE, only.values=TRUE)$values[1]   #compute eigenvalues
  })[3] ;  summa &lt;- summa + timing
} ; times &lt;- summa/nsim
cat(c(&quot;Computation of eig. random matrix 5000x5000 (sec): &quot;, times, &quot;\n&quot;))</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages</h2></hgroup><article  id="parallel-packages-2">

<p>Other packages (doParallel, parallel, doMC, doMPI, doFuture) use a common set of instructions to use parallel capabilities as follows:</p>

<pre class = 'prettyprint lang-r'>library(&quot;package-name&quot;)

cl &lt;- makeCluster(NumberofCores)

register_cluster(cl)

... #code to be run in parallel mode

stopCluster(cl)</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages: examples</h2></hgroup><article  id="parallel-packages-examples">

<p>the <strong>foreach</strong> package is used for executing loops:</p>

<pre class = 'prettyprint lang-r'>library(foreach)
r &lt;- foreach(icount(trials), .combine=cbind) %do% {
      ind &lt;- sample(100,100, replace=TRUE)
      result1 &lt;- glm(x[ind,2]~x[ind,1], family=binomial(logit))
      coefficients(result1)
}</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages: examples</h2></hgroup><article  id="parallel-packages-examples-1">

<p><strong>doParallel</strong> is a backend parallel package for executing code in parallel mode:</p>

<pre class = 'prettyprint lang-r'>library(doParallel)  #using &quot;doParallel&quot; package
cl &lt;- makeCluster(2)
registerDoParallel(cl)
getDoParWorkers()    #this line tells the nr. of workers</pre>

<pre >## [1] 2</pre>

<pre class = 'prettyprint lang-r'>getDoParName()       #this line tell the type of cluster</pre>

<pre >## [1] &quot;doParallelSNOW&quot;</pre>

<pre class = 'prettyprint lang-r'>stopCluster(cl)</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages: examples</h2></hgroup><article  id="parallel-packages-examples-2">

<p><strong>doParallel</strong> can be used to execute <strong>foreach</strong> loops in parallel:</p>

<pre class = 'prettyprint lang-r'>library(doParallel)  #using &quot;doParallel&quot; package
cl &lt;- makeCluster(2)
registerDoParallel(cl)

r &lt;- foreach(icount(trials), .combine=cbind) %dopar% {
      ind &lt;- sample(100,100, replace=TRUE)
      result1 &lt;- glm(x[ind,2]~x[ind,1], family=binomial(logit))
      coefficients(result1)
}

stopCluster(cl)</pre>

</article></slide><slide class=""><hgroup><h2>Parallel packages: examples</h2></hgroup><article  id="parallel-packages-examples-3">

<p><strong>parallel</strong> package</p>

<pre class = 'prettyprint lang-r'>library(parallel)  #using &quot;parallel&quot; package

detectCores()
P &lt;- detectCores(logical = FALSE)  #only physical cores

myfunc &lt;- function(id) { #function to sum by rows
  arguments &lt;- mydata[id, ]
  arguments$one + arguments$two + arguments$three }

cl &lt;- makeCluster(P)   #distribute the work across cores
clusterExport(cl, &quot;mydata&quot;)
res &lt;- clusterApply(cl, 1:N, fun = myfunc)
stopCluster(cl)</pre>

</article></slide><slide class=""><hgroup><h2>Random Numbers in parallel simulations</h2></hgroup><article  id="random-numbers-in-parallel-simulations">

<p>The following simulations <em>res1</em> and <em>res2</em> do not give reproducible results:</p>

<pre class = 'prettyprint lang-r'>library(doParallel)
cl &lt;- makeCluster(2)
registerDoParallel(cl)
set.seed(1)
res1 &lt;- foreach(n = rep(2, 3), .combine=rbind) %dopar% rnorm(n)

set.seed(1)
res2 &lt;- foreach(n = rep(2, 3), .combine=rbind) %dopar% rnorm(n)
stopCluster(cl)
identical(res1,res2)</pre>

<pre >## [1] FALSE</pre>

</article></slide><slide class=""><hgroup><h2>Random Numbers in parallel simulations</h2></hgroup><article  id="random-numbers-in-parallel-simulations-1">

<p>For reproducible parallel simulation a RNG package such as <strong>doRNG</strong> is recommended:</p>

<pre class = 'prettyprint lang-r'>library(doRNG)
cl &lt;- makeCluster(2)
registerDoParallel(cl)
registerDoRNG(1)
res3 &lt;- foreach(n = rep(2, 3), .combine=rbind) %dopar% rnorm(n)

set.seed(1)
res4 &lt;- foreach(n = rep(2, 3), .combine=rbind) %dopar% rnorm(n)
stopCluster(cl)
identical(res3,res4)</pre>

<pre >## [1] TRUE</pre>

</article></slide><slide class=""><hgroup><h2>Profiling Memory: gc (Parallel)</h2></hgroup><article  id="profiling-memory-gc-parallel">

<p>Memory profiling is crucial upon using parallel packages. Suppose we have a data frame <em>mydata</em> which will be processed with the <em>clusterApply</em> function</p>

<pre class = 'prettyprint lang-r'>&gt;gcinfo(TRUE)   #activate gc 
&gt;N &lt;- 5000000
&gt;mydata &lt;- data.frame(one=1.0*seq(N),two=2.0*seq(N),three = 3.0*seq(N))
...
Garbage collection 23 = 14+2+7 (level 0) ... 
43.5 Mbytes of cons cells used (66%)
130.4 Mbytes of vectors used (65%)
&gt;gc()
           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells   572516  30.6    1233268  65.9  1233268  65.9
Vcells 16492769 125.9   26338917 201.0 19085502 145.7</pre>

</article></slide><slide class=""><hgroup><h2>Profiling Memory: gc (Parallel)</h2></hgroup><article  id="profiling-memory-gc-parallel-1">

<p>Then, we use a function to partition the data frame by cores</p>

<pre class = 'prettyprint lang-r'>&gt;library(parallel)  #using parallel package
&gt;detectCores()
&gt;P &lt;- detectCores(logical = FALSE)  #only physical cores

&gt;myfunc &lt;- function(id) { #function to sum by rows
&gt;  arguments &lt;- mydata[id, ]
&gt;  arguments$one + arguments$two + arguments$three
&gt;}</pre>

</article></slide><slide class=""><hgroup><h2>Profiling Memory: gc (Parallel)</h2></hgroup><article  id="profiling-memory-gc-parallel-2">

<pre class = 'prettyprint lang-r'>&gt;cl &lt;- makeCluster(P)   #distribute the work across cores
&gt;clusterExport(cl, &quot;mydata&quot;)
&gt;res &lt;- clusterApply(cl, 1:N, fun = myfunc)
&gt;stopCluster(cl)
...
Garbage collection 1196 = 1128+50+18 (level 0) ... 
312.5 Mbytes of cons cells used (60%)
206.5 Mbytes of vectors used (59%)
&gt; gc()
           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells  5850436 312.5    9776540 522.2  9776540 522.2
Vcells 27062930 206.5   45804848 349.5 42982557 328.0</pre>

<p>the time to execute <strong>myfunc</strong> in parallel mode increases drastically.</p>

</article></slide><slide class=""><hgroup><h2>Good practices</h2></hgroup><article  id="good-practices">

<ul>
<li>Use the login nodes for lightweight tasks</li>
<li>Profile your code</li>
<li>Monitoring your job on the fly:</li>
</ul>

<p>If you run your script on multiple cores, you can monitor the CPU and memory usage in real time, use the following command on the terminal:</p>

<p><strong>job-usage &ldquo;job_ID&rdquo;</strong></p>

<p>Then copy and paste the URL on your local web browser.</p>

</article></slide><slide class=""><hgroup><h2>Good practices</h2></hgroup><article  id="good-practices-1">

<img width="750px" src='Images/job-usage.png' title=''/>

</article></slide><slide class=""><hgroup><h2>Summary</h2></hgroup><article  id="summary">

<ul>
<li><p>Login nodes and Rstudio should be used for lightweight tasks for other tasks use the SLURM batch system <strong>sbatch script</strong></p></li>
<li><p>Compute bound or memory bound programs</p></li>
<li><p>Some packages for instance the linear algebra ones include already implicit parallelism</p></li>
<li><p>It is a good practice to get a profiling analysis (time vs. nr. cores) to request the optimal nr. of cores in your batch script</p></li>
<li><p>Monitor the behavior of your batch job with <strong>job-usage</strong> tool</p></li>
</ul>

</article></slide><slide class=""><hgroup><h2>References</h2></hgroup><article  id="references">

<ul>
<li><a href='https://swcarpentry.github.io/r-novice-inflammation/' title=''>https://swcarpentry.github.io/r-novice-inflammation/</a></li>
<li><a href='https://www.tutorialspoint.com/r/index.htm' title=''>https://www.tutorialspoint.com/r/index.htm</a></li>
<li>R High Performance Programming. Aloysius, Lim; William, Tjhi. Packt Publishing, 2015.</li>
<li><a href='http://adv-r.had.co.nz/memory.html' title=''>http://adv-r.had.co.nz/memory.html</a></li>
<li><a href='https://blogs.oracle.com/r/managing-memory-limits-and-configuring-exadata-for-embedded-r-execution' title=''>https://blogs.oracle.com/r/managing-memory-limits-and-configuring-exadata-for-embedded-r-execution</a></li>
<li><a href='https://rawgit.com/PPgp/useR2017public/master/tutorial.html' title=''>https://rawgit.com/PPgp/useR2017public/master/tutorial.html</a></li>
</ul>

<p><a href='index.html' title=''>Return to Index</a></p></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
